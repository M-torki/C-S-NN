
\section{علم داده چیست؟}
\label{sec:ds}
علم داده 
\LTRfootnote{data science}
جستجو در داده‌ها به منظور اکتشاف و ارائه مدل‌های پیش‌بینی کننده و استخراج علم به صورت مستقیم از داده‌ها است، زمانی که در بزرگ‌مقیاس به داده‌ها توجه شود. این علم عرصه نوظهوری است که در تعاملی میان‌رشته‌ای میان ریاضیات و آمار و علوم کامپیوتر و فیزیک است. در دنیای امروز حجم داده‌ای که در زمینه‌های مختلف وجود دارد بیشتر و بیشتر می‌شود. به طور مثال هر روزه حجم بسیار عظیمی از اطلاعات و داده‌ها در شبکه‌های اجتماعی رد و بدل می‌شود. اگر بخواهیم با استفاده از تحلیل این داده‌ها، به نتایج روان‌شناختی، سیاسی، اجتماعی و... درباره مردم جامعه دست پیدا کنیم و یا حتی بخواهیم تجارتی را تقویت بخشیم این امر مستلزم این است که بدانیم با این حجم از داده چه کنیم و چگونه اطلاعات مفید از آن استخراج کنیم. این کاربردها از علم داده گرچه از نظر نویسنده جذاب است ولی جذابیت آن وقتی بیشتر می‌شود که ردّپایی از فیزیک در این میان پیدا شود. فیزیک امروز به عنوان یکی از پیشگامان تولید داده شناخته می‌شود. اگر اندکی در کیهان‌شناسی و اخترفیزیک نوین تامل کنیم به این نتیجه خواهیم رسید که وجود داده‌ها در قرن گذشته این شاخه‌ها از فیزیک را دگرگون کرده است. ورود کیهان‌شناسی به ورطه علوم دقیق و به عنوان شاخه‌ای از فیزیک پس از اینکه گالیله اولین بار از تلسکوپ برای مشاهده آسمان استفاده کرد صورت گرفت. تلسکوپ‌های جدید بر روی زمین و یا حتی در فضا مشغول داده‌گیری مستمر هستند و نتیجه فعالیت آن‌ها حجم عظیمی از داده رصدی است. پروژه‌های در حال توسعه‌ای نیز در زمینه رصدی وجود دارند که در آینده‌ای نه چندان دور حجم داده بسیار بیشتری در اختیار ما قرار خواهند داد. به طور مثال رصدگر LSST
\LTRfootnote{Large Synoptic Survey Telescope}
در سال ۲۰۲۲ شروع به داده‌گیری خواهد کرد، در حالی که حجم داده‌های دریافتی از این تلسکوپ در هر هفته معادل حجم کل داده‌هایی است که تلسکوپ هابل در ۳۰ سال فعالیت خود جمع‌آوری کرده است. با ورود داده‌های بزرگ به کیهان‌شناسی و نجوم نیاز به علم داده و دانشمندان علم داده (و ترجیحا فیزیکدانانی که ابزار علم داده را بشناسند) بیش از پیش احساس خواهد شد.

\section{یادگیری ماشین}
\label{machine_learning}

یادگیری ماشین یکی از شاخه‌های هوش مصنوعی است که به کشف روش‌هایی می‌پردازد که در آن‌ها ماشین‌ها در راستای هدفی مشخصی آموزش می‌بیند، بدون اینکه برنامه‌نویسی صریح انجام شده‌باشد. برخلاف روش‌های کلاسیک برنامه‌‌نویسی که در آن‌ها یک فرآیند مشخص بر داده‌های ورودی اعمال می‌شود و نتیجه آن خروجی متناظر با ورودی است، در روش‌های یادگیری ماشین داده‌های ورودی و خروجی متناظر با آن‌ها به ماشین داده می‌شود تا ماشین، خود مدلی بهینه استخراج کند که بهترین برازش بین ورودی و خروجی را ارائه و روی مجموعه داده‌های دیده نشده پیش‌بینی انجام دهد. به طور کلی روش‌های یادگیری ماشینی مبتنی بر جستجوی داده‌محور
\LTRfootnote{data deriven}
در فضای پارامترها است. از این رو دسترسی به منابع داده خوب و کافی بسیار حائز اهمیت است. در راستای آموزش ماشین باید مجموعه داده کلی را به دو بخش آموزش و آزمون تقسیم و از بخش آزمون فقط برای ارزیابی مدل استفاده کنیم.  
روش‌های یادگیری در ماشین بسته به فرآیند آموزش به دو دسته مهم تقسیم می‌شوند:
%------------------------------------------------------------------------------------------------------------%
\par
$\bullet$
یادگیری نظارت ‌شده 
\LTRfootnote{Supervised Learning}
: در این نوع از یادگیری هر کدام از داده‌های ورودی برچسب دارند. این یادگیری نظارت شده نامیده می شود زیرا ما پاسخ های صحیح که همان برچسب‌ها هستند را می دانیم و یادگیری از روی مجموعه داده‌های برچسب‌دار می تواند به عنوان یک معلم ناظر بر یادگیری تصور شود. در طول فرآیند آموزش پیش‌بینی‌های ماشین بر روی داده‌ها با مقدار واقعی مقایسه می‌شود و تکرار این فرآیند ماشین را به سمت ساخت یک مدل خوب راهنمایی می‌کند.
%------------------------------------------------------------------------------------------------------------%
\par
$\bullet$
یادگیری بدون نظارت 
\LTRfootnote{Unsupervised Learning}
:با وجود آنکه روش‌های نظارت شده متداول‌ترین نوع یادگیری هستند، اما دسترسی به مجموعه بزرگی از داده‌های برچسب خورده در بعضی کاربردها می‌تواند بسیار سخت و یا حتی غیرممکن باشد. از این رو روش‌های یادگیری بدون نظارت نیز برای تعامل برقرار کردن با این دسته از داده‌های بدون برچسب مورد استفاده اند. از مهم‌ترین کاربردهای یادگیری بدون نظارت، خوشگی
\LTRfootnote{Clustering}
است که در این روش داده‌ها با توجه به ویژگی‌ها و شباهت‌هایشان در خوشه‌های مختلف قرار می‌گیرند.
\par
فرآیندهای متداول دیگری در یادگیری وجود دارند از جمله یادگیری نیمه‌ نظارت شده
\LTRfootnote{Semi-Supervised Learning}
و یادگیری تقویت شده
\LTRfootnote{Reinforcement Learning}
که روش اول در میانه دو روش ذکر شده در بالا است. به این معنی که علاوه بر داده‌های بدون برچسب، ماشین توسط تعدادی داده برچسب‌دار راهنمایی می‌شود و داده‌های برچسب‌دار بخش کوچکی از کل داده‌های آموزشی را شامل می‌شود. روش دوم نیز حیطه دیگری از یادگیری ماشین است که در آن در طی فرآیند یادگیری تعامل با محیط وجود دارد. جزئیات بیشتر درباره این روش را میتوان در 
\cite{sutton1998introduction}
یافت.\\
در کاربردهای یادگیری ماشین و به خصوص یادگیری نظارت شده، با دو دسته مسئله روبرو هستیم: دسته‌بندی
\LTRfootnote{Classification}
و رگرسیون
\LTRfootnote{Regression}
.دسته‌بندی مسائلی را شامل می‌شود که خروجی‌های ماشین یا همان برچسب‌ها، فقط مقادیر گسسته دارند و رگرسیون مربوط به مسائلی است که خروجی ماشین مقادیری پیوسته است.
\par
%------------------------------------------------------------------------------------------------------------%
مدلی که ماشین استخراج می‌کند باید به اندازه لازم و کافی پیچیده باشد. اگر درجات آزادی مدل در مقایسه با حجم داده‌های موجود زیاد باشد ممکن است منجر به برازش بیش از حد 
\LTRfootnote{overfitting}
شود که این مسئله باعث می‌شود که مدل قابلیت تعمیم‌پذیری نداشته باشد، یعنی دقت پیش‌بینی روی داده‌های دیده‌ نشده بسیار کمتر از دقت روی داده‌های آموزش که ماشین آن‌ها را دیده است باشد. 
متقابلا اگر درجات آزادی مدل به نسبت گنجینه داده کم باشد منجر به برازش کمتر از حد 
\LTRfootnote{underfitting}
می‌شود، که به این معنی است که ماشین از تمام قابلیت‌های موجود برای یادگیری استفاده نکرده است و انعطاف پذیری لازم را ندارد که بتواند انحراف از معیار داده‌ها را پوشش دهد.
در مسائل یادگیری ماشینی توازن بین خطای سوییدگی 
\LTRfootnote{bias error}
و خطای واریانس بسیار مهم است. خطای سوییدگی به معنی میزان تفاوت پیش‌بینی‌های ماشین و مقادیر واقعی خروجی است و زیاد بودن آن به این معنی است که دقت ماشین روی هر دو مجموعه داده‌های آموزش و آزمون پایین است. خطای واریانس یک مدلُ گویای میزان پخش بودن مقادیر پیش‌بینی شده به نسبت مقادیر واقعی است. واریانس زیاد به معنی این است که خطا روی داده‌های آموزش بسیار کم است در حالی که خطا روی داده‌های آزمون زیاد است و ماشین جزئیات بیهوده داده آموزش مثل نوفه را به جای مفهوم کلی یاد گرفته‌است.   
مدلی که کمتر از حد برازش شده باشد واریانس کم و سوییدگی زیاد دارد که این دو معیار برای مدلی که بیش‌برازش شده باشد دقیقا حالت عکس دارد.
شکل
 \ref{fig:overfit}
نشان دهنده حالت‌های مختلف برازش است.
%------------------------------------------------------------------------------------------------------------%
 \begin{figure}
	\begin{center}
		\includegraphics[scale=1 , width=\textwidth]{figs/overfitting.png}
	\end{center}
	\caption[نمونه‌ای از برازش‌های غیرمطلوب (راست و چپ) و برازش مطلوب(وسط)]{
		نمونه‌ای از برازش‌های غیرمطلوب (راست و چپ) و برازش مطلوب(وسط)
		\footnotemark.}
	
	\label{fig:overfit}
\end{figure} 
\LTRfootnotetext{https://www.geeksforgeeks.org/underfitting-and-overfitting-in-machine-learning/}
%------------------------------------------------------------------------------------------------------------%

%$$$$$$$$$$$
%$$$$$$$$$$$
%$$$$$$$$$$$
%$$$$$$  DEEP LEARNING   $$$$$$$$$$
%$$$$$$   & FEATURES     $$$$$$$$$$
%$$$$$$$$$$$
%$$$$$$$$$$$

\section{یادگیری عمیق و اهمیت ویژگی‌ها} 
\label{sec:Deep_feature}
%------------------------------------------------------------------------------------------------------------%
\par
موفقیت روش های سنتی یادگیری ماشین به فرایندی مجزّا برای انتخاب ویژگی از داده‌ها وابسته است که داده های خام را به یک بردار ویژگی تبدیل می کند. در فرآیند یادگیری، ماشین می‌تواند با استفاده از این بردار ویژگی الگوهای موجود در ورودی را تشخیص دهد و طبقه‌بندی کند.
\cite{lecun2015deep}
به طور مثال در مقاله
\cite{vafaei2017multiscale} 
آشکارسازی ریسمان‌های کیهانی توسط استخراج ویژگی‌های آماری مانند انحراف‌معیار، ممان‌های مختلف و PDF 
\LTRfootnote{Probability Density Function}
و... انجام شده‌است. 
در برابر، روش‌های دیگری وجود دارند که به ما این امکان را می‌دهند که برای آموزش ماشین از داده های خام استفاده کنیم  و امر خطیر استخراج ویژگی را به ماشین بسپاریم. این کار به ماشین اجازه می‌دهد که در حین آموزش مثلا برای طبقه‌بندی، نمایش‌هایی از داده را حفظ کند که به او در طبقه‌بندی بهتر و دقیق‌تر کمک می‌کند و مابقی را در یادگیری دخیل نکند.
\cite{bengio2013representation}
این ویژگی‌های استخراج شده عموما از نظر ما کاملا غیربدیهی هستند و نخواهیم دانست که دقیقا چه هستند.
در روش‌های مبتنی بر مهندسی ویژگی، این سوال همواره مطرح است که آیا لزوماًبهترین ویژگی‌ها را انتخاب کرده‌ایم؟ آیا ویژگی‌های دیگری وجود ندارند که کمک‌کننده باشند؟ از طرفی استفاده از ویژگی‌های نامناسب هم می‌تواند ماشین را سردرگم و دقت مدل را کمتر و هزینه محاسباتی را بیشتر کند. این مسئله اهمیت روش‌هایی که استخراج داده انجام می‌دهند را مشخص می‌کند. ما دیگر نگرانی بابت انتخاب ویژگی‌های مناسب و بهینه نداریم.
\par
یادگیری عمیق 
\LTRfootnote{Deep Learning}
یکی از زیرمجموعه‌های یادگیری ماشین است که بر پایه الگوریتم شبکه‌های عصبی مصنوعی
\LTRfootnote{Artificial Neural Networks}
ساخته شده است. در این نوع از یادگیری نیازی به انتخاب ویژگی نیست و ماشین با داده‌های خام آموزش می‌بیند. کلمه عمیق در این‌جا اشاره به تعداد زیاد لایه‌های مخفی در شبکه عصبی دارد که در ادامه درباره آن می‌گوییم. 

%------------------------------------------------------------------------------------------------------------%


%$$$$$$$$$$$
%$$$$$$$$$$$
%$$$$$$$$$$$
%$$$$$$  NEURAL NETWORKS  $$$$$$$$$$
%$$$$$$$$$$$
%$$$$$$$$$$$
%$$$$$$$$$$$

\section{شبکه‌های عصبی} 
\label{neural_networks}
%------------------------------------------------------------------------------------------------------------%
یادگیری به روش شبکه عصبی مصنوعی الهام گرفته‌شده از فرآیند یادگیری در مغز انسان است، به وسیله کشف الگوها و با تکرار. در شبکه مغز میلیاردها نورون وجود دارد که به وسیله دندریت‌ها
\LTRfootnote{Dendrites}
 و آکسون‌ها
\LTRfootnote{Axons}
 به یکدیگر متصلند و پیام مخابره می‌کنند. نورون‌ها یا سلول‌های عصبی، با انتقال سیگنال‌های الکتروشیمیایی با بخش‌های مختلف بدن ارتباط برقرار می‌کنند. دندریت اطلاعات خارجی و سیگنال‌ها را دریافت میکند و به نورون انتقال می‌دهد و انتقال‌دهنده‌ی بلندی به نام آکسون از جسم سلولی منشعب می‌شوند که سیگنال‌ها را به دیگر نورون‌ها و یا سلول‌های هدف منتقل می‌کنند. شکل 
 \ref{fig:brain}
 بیانگر شباهت سیستم عصبی انسان با شبکه عصبی مصنوعی است. 
 نورون‌ها اطلاعاتِ ورودی را با هم جمع کرده و اگر به اندازه کافی سیگنال قوی باشد و از یک حدِ آستانه‌ای فراتر رود فعال می‌شود و این سیگنالِ فعالْ شده از طریق آکسون‌ها به نورون‌های دیگر متصل می‌شود. در غیر اینصورت اگر سیگنال ضعیف باشد فعال نمی‌شود.  
%------------------------------------------------------------------------------------------------------------%
 \begin{figure}
	\begin{center}
		\includegraphics[scale=0.8 , width=\textwidth]{figs/brainvsann.png}
	\end{center}
	\caption[شباهت میان شبکه عصبی مصنوعی و طبیعی.]{
		شباهت میان شبکه عصبی مصنوعی و طبیعی.
		
		\footnotemark.}
	
	\label{fig:brain}
\end{figure} 
%------------------------------------------------------------------------------------------------------------%
مشابه فرآیندی که در مغز اتفاق می‌افتد، شبکه عصبی مصنوعی از یک لایه ورودی و یک لایه خروجی تشکیل شده است که میان این دولایه می‌تواند یک یا چند و یا چندین لایه مخفی حضور داشته باشند. هر لایه از تعدادی نورون تشکیل شده است. لایه ورودی شامل همان داده‌های ورودی ماشین است که با $x_i$ نمایش داده‌ می‌شوند و هر $x$ وزن متناظر $w_i$ دارد و مجموع وزن‌دار نورون‌های ورودی در نهایت بعد از اعمال شدن یک تابع فعال‌سازی روی آن، به لایه بعدی وارد می‌شود و فراآیند جمع وزن‌دار در لایه‌های بعدی نیز به همین شکل ادامه پیدا می‌کند. یادگیری در یک شبکه عصبی به معنی پیدا کردن مقادیر مناسب این وزن‌هاست به صورتی که ارتباط بین ورودی و خروجی را به بهترین شکل توصیف کند. اگر نورون‌های لایه دوم را با $y$ نشان دهیم رابطه زیر برای $y_i$ برقرار است:
%------------------------------------------------------------------------------------------------------------%
\begin{equation}
y_i =F( \sum{w_i x_i} + b )
\end{equation}
%------------------------------------------------------------------------------------------------------------%
که در این معادله $F$ بیان‌گر یک تابع فعال‌سازی
\LTRfootnote{Activation Function}
و $b$  مقدار سوییدگی است. در ادامه به معرفی مفاهیم اصلی در یک شبکه عصبی ساده می‌پردازیم. \\
%------------------------------------------------------------------------------------------------------------%
\textbf{نورون}
: بنیادی‌ترین بخش یک شبکه عصبی نورون‌ها هستند که ورودی را دریافت کرده، و پس از فعال‌سازی خروجی متناظر را تحویل می‌دهد. این خروجی می‌تواند به لایه بعدی وارد شود و یا خروجی نهایی شبکه باشد.\\
 \begin{figure}[H]
	\begin{center}
		\includegraphics[scale=0.3]{figs/neuron.png}
	\end{center}
	\caption[تصویر شماتیک یک نورون.]{
		تصویر شماتیک یک نورون.
		
		\footnotemark.}
	
	\label{fig:neuron}
\end{figure} 
%------------------------------------------------------------------------------------------------------------%
\textbf{وزن‌ها}
هر نورون در یک وزن ضرب می‌شود که میزان اهمیت آن نورون را مشخص می‌کند. نورون‌های با وزن بزرگتر در یادگیری ماشین کارآمدتر هستند در حالی که نورون‌ها با وزن صفر کم‌ارزش‌تر هستند. وزن‌های شبکه در ابتدا به صورت کاملا تصادفی مقداردهی می‌شوند ولی در ادامه و در طی فرآیند یادگیری وزن‌ها در مسیری مقداردهی می‌شوند که یک تابع هزینه را کمینه کنند و پیش‌بینی‌های دقیق‌تری ارائه دهند. \\
%------------------------------------------------------------------------------------------------------------%
\textbf{بایاس یا سوییدگی}
: مولفه خطی دیگری است که به صورت قراردادی به جمع وزن‌دار سایر ورودی‌ها اضافه می‌شود تا گستره مقادیر خروجی را تغییر دهد. سوییدگی مانند مقدار ثابت در توابع چندجمله‌ای است که باعث می‌شود همه مقادیر از مبدا عبور نکنند و مدل قابلیت سازگاری بیشتری با داده پیدا کنند. اضافه کردن سوییدگی معادل این است که یک نورون با مقدار ۱ را به لایه اضافه کرده باشیم که نام وزن متناظر با آن به جای  $w$ ،با $b$ نمایش داده شود. \\

%------------------------------------------------------------------------------------------------------------%
 \begin{figure}
	\begin{center}
		\includegraphics[scale=0.01 , width=\textwidth]{figs/NN.jpeg}
	\end{center}
	\caption[.  $w_{ki}$
	ها در این شکل وزن‌های متناظر با ورودی‌های 
	$x_i$
	هستند . تابع فال‌سازی روی جمع وزن‌دار ورودی‌ها($V_k$) اعمال می‌شود و خروجی لایه که $y_k$ است را می‌دهد.نمای یک لایه از شبکه عصبی]{
		نمای یک لایه از شبکه عصبی
		\cite{bansal2009matlab}. 
		 $W_{ki}$
		ها در این شکل وزن‌های متناظر با ورودی‌های 
		$X_i$
		هستند. تابع فعال‌سازی روی جمع وزن‌دار ورودی‌ها($V_k$) اعمال می‌شود و خروجی لایه که $Y_k$ است را می‌دهد. 
	}
	
	\label{fig:NN}
\end{figure} 
%------------------------------------------------------------------------------------------------------------%
\textbf{تابع فعال‌سازی}
: همانطور که پیش‌تر اشاره شد تابع فعال‌سازی وظیفه غیرخطی کردن مدل را به عهده دارد. این تابع است که مشخص می‌کند در نهایت چه مقادیری اجازه ورود به لایه بعدی را دارند و کدام مقادیر باید حذف شوند. در هر لایه اعمال شدن تابع فعال‌سازی پیچیدگی مدل را بیشتر می‌کند و باعث می‌شود که مدل انعطاف لازم را برای سازگاری با داده پیدا کند. بدون فعال‌سازی مدل خطی خواهد بود در حالی که مدلی که به حقیقت نزدیک‌تر است لزوما خطی نیست.
توابع فعال‌سازی متداولی در که حیطه یادگیری ماشین بیشتر استفاده می‌شوند عبارتند از:
%------------------------------------------------------------------------------------------------------------%
\begin{latin}
	
Sigmoid:$\frac{1}{1+e^{-x}}$,\\ 
Softmax: $\frac{e^{x_i}}{\sum{e^{x_i}}}$,\\
Rectified Linear Unit(Relu): max(0,x), \\
Tanh: $\frac{e^{x}-e^{-x}}{e^{x}+e^{-x}}$.

\end{latin}

\cite{nwankpa2018activation}   
%------------------------------------------------------------------------------------------------------------%
شکل 
\ref{fig:NN}
نشان‌دهنده یک شبکه عصبی کاملا همبند ساده است: شامل نورون، وزن، سوییدگی و تابع فعال‌سازی.  
  \section{تابع هزینه و بهینه‌سازی}
  \subsection{تابع هزینه}
  \LTRfootnote{Cost or loss Function}
  یک ویژگی مهم در هر شبکه عصبی خط و مشیی است که شبکه برای یادگیری دارد. تابع هزینه معیاری است که شبکه بر اساس آن آموزش می‌بیند و . فرآیند یادگیری بر اساس کمینه کردن تابع هزینه صورت می‌گیرد. در ابتدا وزن‌های شبکه به صورت تصادفی مقداردهی و بر اساس آن وزن‌ها مقدار تابع هزینه مشخص می‌شود. سپس در گام تکرار بعدی وزن‌ها به صورتی مقداردهی می‌شوند که تابع هزینه از گام قبلی مقدار کمتری پیدا کند. تکرار این فراآیند تا جایی ادامه پیدا می‌کند که مقدار هزینه همگرا شود و مقدار کمتری پیدا نکند و یا به مقدارآستانه‌ای که ما مشخص کرده‌ایم برسد. چندی از توابع هزینه متداول برای شبک‌های عصبی را معرفی می‌کنیم: 
  %------------------------------------------------------------------------------------------------------------%
  \begin{latin}
  	
  	\textbf{Mean Squared Error(MSE):}
  	\begin{equation}
  	L = \frac{1}{n} \sum_{i=1}{ (y_i - \hat{y}_i)^{2}}
  	\end{equation}
  	%------------------------------------------------------------------------------------------------------------%
  	
  	\textbf{Cross-Entropy Loss:}
  	\begin{equation}
  	L =-\frac{1}{n}\sum_{i=1}^{n}\big[y^{(i)}\log(\hat{y}^{(i)})+(1-y^{(i)})\log(1-\hat{y}^{(i)})\big]
  	\label{CE_loss}
  	\end{equation}
  	%------------------------------------------------------------------------------------------------------------%
  	\textbf{Huber-Loss:}
  	\begin{align}
  	L(y,f(x)) = \left\{ \begin{array}{cl}
  	\frac{1}{2} \left[y-f(x)\right]^2 & \text{for }|y-f(x)| \le \delta, \\
  	\delta \left(|y-f(x)|-\delta/2\right) & \text{otherwise.}
  	\end{array}\right.
  	\label{huber_loss}
  	\end{align}
  \end{latin}
  %------------------------------------------------------------------------------------------------------------%
  
  تعداد بسیار زیادی از توابع هزینه در یادگیری ماشین وجود دارد که بسته به کاربردهای مختلف انتخاب‌های متعددی داریم که گاهی نیاز به کمی سعی و خطا برای پیدا کردن مناسب‌ترین تابع نیاز داریم.
  
  %------------------------------------------------------------------------------------------------------------%
  \begin{figure}[h!]
  	\begin{center}
  		\includegraphics[scale=0.35]{figs/local_optima.png}
  	\end{center}
  	\caption[یادگیری ایده‌آل در مسائل یادگیری ماشین یعنی پیدا کردن کمینه سراسری و یا کمینه موضعیِ به اندازه کافی خوب   به اندازه کافی بهینه باشد.]{
  		یادگیری ایده‌آل در مسائل یادگیری ماشین یعنی پیدا کردن کمینه سراسری و یا کمینه موضعیِ به اندازه کافی خوب   که به اندازه کافی بهینه باشد.   
  		
  		\cite{goodfellow2016deep}
  	}
  	\label{fig:local_optima}
  \end{figure} 
  
  \subsection{نرخ یادگیری}
  \LTRfootnote{Learning Rate}
  یکی از پارامترهای ویژه‌ای است که توسط کاربر باید مشخص شوند و ماشین آن را انتخاب نمی‌کند. این پارامتر مشخصص می‌کند که در هر گام تکرار یادگیری با توجه به تغییرات تابع هزینه وزن‌ها چقدر باید عوض شوند. نرخ یادگیری عددی بین ۰ و۱ است. مقدار خیلی کوچک برای این پارامتر می‌تونند سرعت یادگیری را بسیار کم کند و مقدار بزرگ آن ممکن است منجر به گیر افتادن در یک کمینه موضعی شود. شکل 
  \ref*{fig:LR}
  بیان‌گر این موضوع است.
  معمولا برای شروع مقداری  حدودا $0.001$ و یا کمی  بیشتر مناسب است و این مقدار به تدریج کمتر می‌شود. نحوه اثرگذاری نرخ یادگیری بر تغییرات وزن بر اساس گرادیان هزینه در رابطه زیر نمایش داده شده است:
  \begin{equation}
  w_{ij}^{*} = w_{ij} + \alpha \frac{\partial{L(w_{ij})}}{\partial{w_{ij}}}
  \end{equation}
  که در این رابطه $w_{ij}$ وزن متناظر بین نورون‌های $i$ و $j$ ،
  $\alpha$
  نرخ یادگیری و $L$ معرف تابع هزینه است. سمت چپ رابطه مقدار جدید وزن را مشخص می‌کند.
  %------------------------------------------------------------------------------------------------------------%
  \begin{figure}[h!]
  	\begin{center}
  		\includegraphics[scale=0.35]{figs/learningrates.jpeg}
  	\end{center}
  	\caption[تاثیر مقادیر مختلف نرخ یادگیری بر فرآیند آموزش. نرخ یادگیری کوچک زمان لازم برای همگرایی را افزایش می‌دهد و مقادیر بزرگ موجب همگرا شدن به یک کمینه موضعی می‌شود. نرخ یادگیری بسیار بزرگ حتی ممکن است باعث واگرایی شود. ]{
  		تاثیر مقادیر مختلف نرخ یادگیری بر فرآیند آموزش. نرخ یادگیری کوچک زمان لازم برای همگرایی را افزایش می‌دهد و مقادیر بزرگ موجب همگرا شدن به یک کمینه موضعی می‌شود. نرخ یادگیری بسیار بزرگ حتی ممکن است باعث واگرایی شود.
  		
  		\footnotemark
  	}
  	\label{fig:LR}
  \end{figure} 
  \LTRfootnotetext{http://cs231n.github.io/neural-networks-3/}
  %------------------------------------------------------------------------------------------------------------%
  مدلی که یک شبکه عصبی می‌سازد، یک مدل با تعداد بسیاری از پارامترهای آزاد است. تعداد این پارامترها از چند هزار تا چندین میلیون و حتی بیشتر متغیر است. پارامترهای آزاد مدل را وزن‌های شبکه مشخص می‌کنند. فرآیند یادگیری در شبکه عصبی به معنی پیدا کردن بهترین برازش برای همه پارامترهای آزاد است پس ما با یک مسئله بهینه‌سازی طرف هستیم. تفاوت بهینه‌سازی در یادگیری ماشین با بهینه‌سازی‌های کلاسیک  بهینه‌سازها در شبکه‌های عصبی روش‌ها و الگوریتم‌هایی هستند که ویژگی‌های شبکه مانند وزن‌ها و نرخ یادگیری را تغییر می‌دهند به نحوی که موجب کاهش مقدار تابع هزینه شود. بهینه‌ساز در شبکه چگونگی تغییر کردن وزن‌ها را مشخص می‌کند. انواع مختلفی از بهینه‌ساز‌ها وجود دارند که استفاده از آن‌ها در مسائل شبکه عصبی متداول است. در ادامه به دو نوع از متداول‌ترین الگوریتم‌های بهینه‌سازی اشاره می‌کنیم.
  \subsection{بهینه‌سازی}
  \begin{itemize}
  	\item
  	\lr{Gradient Descent} (گرادیان کاهشی)
  	: در این روش با مشتق درجه اول تابع هزینه سروکار داریم. این روش مشخص می‌کند که وزن‌ها در چه مسیری باید تغییر کنند تا مقدار هزینه کم شود. این الگوریتم به این شکل است:
  	\begin{equation}
  	\theta_{new} = \theta - \alpha \nabla J(\theta)
  	\end{equation} 
  	$\alpha$ 
  	نرخ یادگیری و $J$تابع هزینه است. از مزایای این بهینه‌ساز سادگی در پیاده‌سازی و محاسبه، و معایب آن سرعت پایین همگرا شدن و نیاز داشتن به حافظه بالا برای محاسبه گرادیان است. روش دیگری نیز به عنوان گرادیان کاهشی تصادفی وجود دارد که تناوب تغییر دادن وزن‌ها در آن بسیار بیشتر است و به جای اینکه از تمام داده‌ها برای بهینه‌سازی تابع هزینه استفاده کند از بخشی از داده‌های آموزشی به صورت تصادفی برای آموزش بهره می‌گیرد. 
  	\item  \lr{Adaptive Moment Estimation(Adam)}
  	: یکی از انواع الگوریتم‌های گرادیان کاهشی تصادفی، Adam است که سرعت همگرایی بالاتری دارد و حافظه مورد نیاز آن نیز برای محاسبه کمتر است. در این روش از گشتاور
  	\LTRfootnote{Moment}
  	اول و دوم گرادیان یعنی میانگین و واریانس برای بهینه‌سازی استفاده می‌شود. 
  	الگوریتم آن به این شکل است:
  	\cite{kingma2014adam}	
  	\begin{flalign}
  	\begin{aligned}
  	&  	while \; not \; converged:&\\
  	&t+1 \leftarrow t& \\
  	&m_\theta ^ {(t+1)} \leftarrow \beta_1 m_\theta ^ {(t)} + (1 - \beta_1) \nabla _\theta J ^ {(t)} &\\
  	&v_\theta ^ {(t+1)} \leftarrow \beta_2 v_\theta ^ {(t)} + (1 - \beta_2) (\nabla _\theta J ^ {(t)} )^2& \\	
  	&\hat{m}_\theta = \frac{m_\theta ^ {(t+1)}}{1 - (\beta_1) ^{t+1}}& \\
  	&\hat{v}_\theta = \frac{ v_\theta ^ {(t+1)}}{1 - (\beta_2) ^{t+1}}& \\
  	&\theta ^ {(t+1)} \leftarrow \theta ^ {(t)} - \alpha \frac{\hat{m}_\theta}{\sqrt{\hat{v}_\theta} + \epsilon} &
  	\end{aligned}&&&
  	\end{flalign}
  	در اینجا t معرف گام زمانی،
  	$\alpha$
  	نرخ یادگیری است. 
  	$\beta_1$
  	و
  	$\beta_2$
  	نرخ کاهش نمایی برای تخمین گشتاورها، اعدادی بین ۰ و ۱ هستند که مقدار پیش‌فرض آن‌ها
  	$\beta_1 = 0.9$ 
  	و
  	$\beta_2 = 0.999$
  	است. $m$ نیز میانگین و $v$ نشانگر واریانس است. 
  	$\epsilon$
  	نیز عددی بسیار کوچک است که از صفر شدن مخرج جلوگیری کند. خروجی این الگوریتم وزن جدید را نتیجه می‌دهد. بهینه‌سازی با  Adam  متداول‌ترین و بهترین روش بهینه‌سازی در شبکه‌های عصبی ژرف است. 
  	
  	
  \end{itemize}
  %------------------------------------------------------------------------------------------------------------%
%$$$$$$$$$$$
%$$$$$$$$$$$
%$$$$$$$$$$$
%$$$$$$  CNN  $$$$$$$$$$
%$$$$$$$$$$$
%$$$$$$$$$$$
%$$$$$$$$$$$

\section{شبکه‌های عصبی پیچشی} 
\label{cnn}
شبکه‌های عصبی پیچشی
\LTRfootnote{Convolutional Neural Networks}
 یکی از الگوریتم‌های پرکاربردی است که به صورت گسترده در تشخیص، طبقه‌بندی و الگویابی تصاویر استفاده می‌شود. یک شبکه پیچشی تصویر را دریافت می‌کند و توانایی آن را دارد که آن را پردازش و در دسته‌های معینی طبقه‌بندی کند. رایانه‌ها تصاویر را به شکل آرایه‌‌ای از پیکسل‌ها می‌بینند که اندازه آن به وضوح و کیفیت تصویر بستگی دارد. این آرایه به شکل (ارتفاع ، عرض ، بعد) است. تصاویر سیاه و سفید به ازای هر پیکسل یک تک مقدار دارند، در حالی که تصاویر رنگی به ازای هر پیکسل ۳ مقدار دارا هستند. پس عدد سوم یا بعد تصویر همواره ۱ یا ۳ است.
\\
از نظر فنی یک شبکه پیچشی عمیق، تصویر ورودی را (چه مریوط به داده آموزش باشد و چه آزمون) از میان تعدادی لایه پیچشی 
\LTRfootnote{Convolution}
با تعدادی فیلتر، لایه‌های ادغام
\LTRfootnote{Pooling}
 و کاملا همبند به همراه توابع فعال‌سازی عبور می‌دهد تا تصویر را با نسبت دادن عددی احتمالی بین صفر و یک در بین کلاس‌ها طبقه‌بندی کند.
\cite{aloysius2017review}
%-----------------------------------------
 \begin{figure}[h!]
	\begin{center}
		\includegraphics[scale=0.45]{figs/convnet.jpeg}
	\end{center}
	\caption[یک شبکه عصبی پیچشی برای طبقه‌بندی تصاویر وسایل نقلیه. در لایه‌های پیچشی و ادغام ویژگی‌ها استخراج می‌شوند و ماشین ویژگی‌ها را می‌آموزد و طبقه‌بندی در نهایت در لایه‌های کاملا همبند رخ می‌دهد.]{
		یک شبکه عصبی پیچشی برای طبقه‌بندی تصاویر وسایل نقلیه. در لایه‌های پیچشی و ادغام ویژگی‌ها استخراج می‌شوند و ماشین ویژگی‌ها را می‌آموزد و طبقه‌بندی در نهایت در لایه‌های کاملا همبند رخ می‌دهد.
		\footnotemark}
	\label{fig:convnet}
\end{figure}    
\LTRfootnotetext{https://medium.com/@RaghavPrabhu/understanding-of-convolutional-neural-network-cnn-deep-learning-99760835f148}
%-----------------------------------------
\subsection{لایه پیچشی}

%-----------------------------------------
\begin{figure}[h!]
	\begin{center}
		\includegraphics[scale=0.35]{figs/convfilter.png}
	\end{center}
	\caption[
	اعمال فیلتر به ابعاد
	۳$\times$۳
	بر تصویر
	۵$\times$۵ 
	در لایه پیچشی.]
	{
		اعمال فیلتر به ابعاد
		۳$\times$۳
		بر تصویر
		۵$\times$۵ 
		در لایه پیچشی
		\footnotemark}
	\label{fig:convfilter}
\end{figure}    

%-----------------------------------------

لایه پیچشی اولین لایه استخراج ویژگی از تصویر ورودی است. این لایه رابطه بین پیکسل ها را با یادگیری ویژگی های تصویر با استفاده از مربع های کوچک از داده های ورودی حفظ می کند. پیچش یا کانولوشن یک عملگر ریاضی است که یک «فیلتر» با اندازه داده شده را بر روی ماتریس تصویر ورودی پیمایش می‌شود و خروجی آن برای هر قسمت از تصویر که فیلتر بر روی آن قرار می‌گیرد ضرب ماتریسی فیلتر در آن بخش از تصویر (هم‌اندازه با فیلتر) است. شکل 
\ref{fig:convfilter}
نشان‌دهنده پیچش یک فیلتر
 ۳$\times$۳
 در تصویر
 	۵$\times$۵ 
 	است.
 	\LTRfootnotetext{https://www.jeremyjordan.me/convolutional-neural-networks/}
 	 به خروجی لایه پیچشی، نقشه ویژگی
	\LTRfootnote{feature map} 
 	 می‌گویند.  
با اضافه کردن پیکسل‌هایی که مقادیر همگی آن‌ها صفر است در دور تا دور یک تصویر ورودی می‌توان ابعاد ورودی و خروجی را در لایه پیچشی یکسان نگه داشت. به این عمل «لایه‌گذاری صفر»
\LTRfootnote{zero-padding} 
می‌گویند. اگر این کار را انجام ندهیم ابعاد تصویر در اثر پیچش کم می‌شود. «گام حرکت» 
\LTRfootnote{stride} 
فیلتر بر روی تصویر نیز کمیتی است که اندازه خروجی لایه را تحت تاثیر قرار می‌دهد.اگر اندازه گام ۱ باشد، فیلتر بعد از اعمال روی اولین ناحیه از تصویر، روی پنجره ای در تصویر عمل می‌کند که نقطه شروع آن دقیقا پیکسل بعدی است. اما اگر گام ۲ باشد نقطه شروع دو پیکسل جلوتر می‌رود و در اثر این نوع حرکت یک در میان ابعاد تصویر خروجی کم‌تر از ورودی می‌شود. در لایه پیچشی معمولا از یک تابع فعال‌سازی جهت به وجود آوردن اثرات غیرخطی استفاده می‌شود.
\subsection{لایه ادغام}
%-----------------------------------------
\begin{figure}[h!]
	\begin{center}
		\includegraphics[scale=0.35]{figs/pooling.jpeg}
	\end{center}
	\caption[
	ورودی یک لایه ادغام (نقشه ویژگی) سمت چپ و خروجی آن در سمت راست نشان داده شده است. ابعاد کرنل 
	۲$\times$۲
	و گام حرکت کرنل ادغام در اینجا ۲ است که سبب شده است که هم‌پوشانی وجود نداشته باشد. ماتریس بالا حاصل از یک ادغام بیشنه و ماتریس پایین حاصل ادغام میانگین است.]
	{
		ورودی یک لایه ادغام سمت چپ و خروجی آن در سمت راست نشان داده شده است. ابعاد کرنل 
		۲$\times$۲
		و گام حرکت کرنل ادغام در اینجا ۲ است که سبب شده است که هم‌پوشانی وجود نداشته باشد. ماتریس بالا حاصل از یک ادغام بیشنه و ماتریس پایین حاصل ادغام میانگین است.
		\footnotemark}
	\label{fig:pooling}
\end{figure}    
\LTRfootnotetext{https://www.quora.com/What-is-max-pooling-in-convolutional-neural-networks}
%-----------------------------------------  
لایه ادغام برای کم کردن تعداد پارامترها استفاده می‌شود و زمانی که تصاویر ورودی بزرگ باشند به ساده کردن و حل مسئله کمک خواهد کرد. این لایه با حفظ اطلاعات مهم در تصویر ابعاد را کوچک می‌کند. به طور مثال در مسئله پیش‌بینی تنش ریسمان از روی نقشه تابش زمینه، ورودی‌های ما تصاویری به ابعاد 
256$\times$256
 هستند که لازم است یک بردار به آن‌ها متناظر شود. پس کاهش ابعاد در تصویر لازمه حل مسئله است. لایه ادغام نیز همانند لایه پیچشی با حرکت دادن یک فیلتر بر روی تصویر فرآیند ادغام را انجام می‌دهد. با این تفاوت که با اعمال فیلتر بر روی قسمت‌های مختلف تصویر میانگین، بیشینه و یا جمع مقادیر داخل آن فیلتر را به عنوان خروجی تحویل می‌دهد. اندازه گام حرکت نیز پارامتر تعیین کننده‌‌ی دیگری در این لایه است. شکل 
 \ref{fig:pooling}
 نشان دهنده ادغام میانگین و بیشینه است.

\subsection{لایه بهنجارش}
آرایه تصاویر ورودی مقادیر دلخواهی به ازای هر پیکسل دارد. مثلا در یک تصویر ممکن است مقادیر از ۰ تا ۱۰ و در دیگری در بازه ۰ تا ۱۰۰ باشد. با بهنجار کردن مقادیر ورودی سرعت یادگیری افزایش پیدا می‌کند و در دقت ماشین نیز تاثیر شگرفی ایجاد می‌شود. بهنجار کردن، که انواع مختلفی نیز دارد، یکی از پیش‌پردازش‌های مهم در شبکه‌های عصبی است. حتی اگر داده ورودی شبکه را بهنجار کنیم باز هم خروجی‌های لایه‌های مختلف و نقشه‌های ویژگی بهنجار نخواهند بود. اگر بهنجار کردن داده ورودی در یادگیری ماشین تاثیر مثبتی دارد، پس چرا همین ایده را برای تمام لایه‌ها به کار نگیریم؟ لایه بهنجارشِ دسته
\LTRfootnote{Batch Normalization}
ورودی‌هایش را با کم کردن مقدار میانگین و تقسیم کردن بر انحراف معیار، استاندارد و بهنجار می‌کند. این لایه علاوه بر سرعت بخشیدن به یادگیری از برازش بیش از حد نیز جلوگیری می‌کند.
\cite{ioffe2015batch}


