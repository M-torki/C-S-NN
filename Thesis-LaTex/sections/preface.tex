
کیهان‌شناسی در قرن اخیر شکل تازه‌ای به خود گرفته است که در اثر وارد شدن داده‌های بزرگ رصدی است. داده‌هایی که ماهواره پلانک، رصدگر اقلیدس و آرایه کیلومتر مربع
\LTRfootnote{square kilometer array}
 و در آینده‌ای نه چندان دور رصدگر LSST
 \LTRfootnote{Large Synoptic Survey Telescope}
 ، با خود به ارمغان می‌آورند. حجم داده‌ای که رصدگر LSST در آینده دریافت خواهد کرد در یک هفته معادل حجم داده ایست که تلسکوپ هابل در ۳۰ سال فعالیت خود دریافت کرده است. کار کردن با این حجم از داده مستلزم این است که بدانیم چگونه با داده‌ها سروکار داشته باشیم و از آن‌ها علم استخراج کنیم. علم داده، یکی از درگاه‌های روش‌شناسی علمی در قرن حاضر است که امروزه آوازه آن از همه جا به گوش می‌رسد. در پزشکی، اقتصاد، علوم انسانی و حتی در زمینه تجارت. اما کاربردهای علم داده در فیزیک نیز امروزه بسیار قابل توجه است. کافی است جستجوی کوتاهی در تحقیقات روز و مقاله‌های اخیر فیزیک داشته باشیم تا متوجه تعامل بین فیزیک و علوم داده بشویم. فیزیک امروزه به عنوان تولیدکننده داده‌های بزرگ شناخته می‌شود و لذا لازم است ابزار علم داده را نیز به خوبی بشناسیم. یادگیری ماشین یکی از زیرشاخه‌های علم داده و هوش مصنوعی است که به ماشین‌ها قدرت یادگیری می‌دهد. البته نه با روش‌های سنتی در برنامه‌نویسی که ورودی و الگوریتم را به ماشین بدهیم و بخواهیم خروجی را از ماشین دریافت کنیم. در یادگیری ماشین ورودی‌ و خروجی متناظر با آن به ماشین داده می‌شود تا ماشین خود در طی مراحل یادگیری مدلی بسازد که بهترین برازش را بین ورودی و مقدار هدف ارائه کند. در این تحقیق از شبکه‌های عصبی 
\LTRfootnote{Neural Networks}
که ابزاری در یادگیری عمیق است استفاده می‌کنیم. ایده الگوریتم‌های شبکه‌های عصبی الهام‌گرفته از فرآیند یادگیری در مغز انسان است. \\
مسئله‌ای که در این تحقیق به دنبال حل آن هستیم، یافتن ردپای ریسمان‌های کیهانی بر تابش زمینه کیهانی است. ریسمان‌های کیهانی نقیصه‌های توپولوژیکی هستند که ممکن است در کیهان اولیه و در اثر شکست تقارن ناشی از پایین آمدن دما به وجود آمده باشند. 
\cite{kibble1976topology , kibble1980some , hindmarsh1995cosmic}.
ریسمان‌ها ساختارهای یک بعدی هستند که شدت آن‌ها را با کمیت بی‌بعدی به نام تنش
\LTRfootnote{tension}
 ریسمان یا $G\mu$ پرمایش می‌کنیم که $\mu$ چگالی بر واحد خط ریسمان و G ثابت گرانش است. از آن‌جایی که ریسمان‌ها تا کنون مشاهده نشده اند پس مقدار $G\mu$ ریسمان نمی‌تواند از حدی بیشتر باشد و باید در مقادیر کوچک به دنبال آن بگردیم. وجود ریسمان‌های کیهانی در بسیاری از مدل‌های تورمی پیش‌بینی شده اند و مشاهده آن‌ها می‌تواند دریچه جدیدی به سوی کیهان اولیه باشد و به بررسی نظریات موجود کمک کند. ریسمان‌ها در صورت وجود ردپاهایی از خود به جا می‌گذارند. بخشی از این ردپاها اثرات ناهمسانگردی در دمای تابش زمینه است. به طور خاص ما در این تحقیق به دنبال کردن اثر گات-کایزر-استبینز
\LTRfootnote{Gott-Kaiser-Stebbins effect}
 یا GKS ریسمان‌ها علاقه‌مند هستیم. 
  \cite{kaiser1984microwave, gott1985gravitational}
این پدیده در اثر حرکت ریسمان‌های پرسرعت رخ می‌دهد و در نتیجه آن ناپیوستگی‌های خط-مانند در تابش زمینه به وجود می‌آید. اثر GKS را به صورت زیر می‌توانیم بیان کنیم:
\begin{equation}
	\frac{\delta T}{T} \sim 8\pi
	G\mu v_{\uS},
\end{equation}
که در اینجا $v_s$ سرعت عمود بر راستای دید ناظر است. افت‌وخیر در دمای فوتون‌ها با تنش ریسمان رابطه مستقیم دارد. \\
در این تحقیق ما با استفاده از سه دسته شبیه‌سازی شبه نسل چهارم تابش زمینه، شبه تلسکوپ کیهان‌شناسی آتاکاما و شبه پلانک برای تابش زمینه کیهانی و از شبکه ریسمانی نامبو-گاتو برای شبیه‌سازی ریسمان استفاده می‌کنیم تا به یک نقشه تابش زمینه در حضور ریسمان برسیم. سپس از شبکه‌های عصبی پیچشی برای آموزش ماشین استفاده می‌کنیم تا ماشین مقدار تنش موجود در نقشه ورودی را حدس بزند. پس از اینکه ماشین را بر روی داده‌های شبیه‌سازی آموزش دادیم، مدل ساخته شده را بر داده‌های رصدی اعمال می‌کنیم تا ماشین تنش ریسمان موجود در آن را حدس بزند. 
\par
در فصل 
\ref{ch:cmb}
مروری خواهیم داشت بر مدل استاندارد کیهان‌شناسی و تابش زمینه کیهانی. در فصل
\ref{ch:cosmic_string}
درباره ریسمان و ردپاهایش خواهیم خواند. در فصل بعد آن یعنی فصل 
\ref{ch:deep_learning}
ابزار استفاده شده در این تحقیق، یعنی یادگیری عمیق و شبکه‌های عصبی را معرفی می‌کنیم. در فصل
\ref{ch:simulations}
شبیه‌سازی‌های استفاده شده در این تحقیق را معرفی خواهیم کرد. در نهایت در فصل 
\ref{ch:detection_pipeline}
روش انجام گرفته برای آموزش ماشین و یافتن ریسمان را به همراه نتایج به دست آمده برای آزمایش‌های مختلف شرح خواهیم داد. در فصل آخر 
(\ref{ch:conclusion})
نیز آنچه در این تحقیق صورت گرفته است را جمع‌بندی می‌کنیم.


